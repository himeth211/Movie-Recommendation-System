{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzYIeuX/cQ2Se3PBrLVZgs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from scipy.sparse import hstack, csr_matrix\n","import ast\n","from bs4 import BeautifulSoup\n","import requests\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer"],"metadata":{"id":"mfZuc_D-nLV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vh4SPg352ojX","executionInfo":{"status":"ok","timestamp":1767180321721,"user_tz":-330,"elapsed":29103,"user":{"displayName":"Himeth Sigera","userId":"17456125594711327945"}},"outputId":"2f221f66-0e3c-44eb-83c0-2fc5dace2073"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Movie Title: American Psycho\n"]}],"source":["movie_title = input(\"Enter Movie Title: \").title()\n","API_KEY = '40aef168ab16c2f7c59380272ba1b17e'\n","BASE_URL = 'https://api.themoviedb.org/3'\n","\n","def get_movie_details(movie_name):\n","    # Search for the movie\n","    search_url = f\"{BASE_URL}/search/movie\"\n","    params = {\n","        'api_key': API_KEY,\n","        'query': movie_name\n","    }\n","\n","    response = requests.get(search_url, params=params)\n","    results = response.json().get('results')\n","\n","    if not results:\n","        return \"No movie found.\"\n","\n","    # Get the ID of the first result\n","    first_movie = results[0]\n","    movie_id = first_movie['id']\n","\n","    # Fetch full details using the movie ID\n","    detail_url = f\"{BASE_URL}/movie/{movie_id}\"\n","    detail_params = {'api_key': API_KEY}\n","    actual_url = f\"https://www.themoviedb.org/movie/{movie_id}\"\n","\n","    movie_details = requests.get(detail_url, params=detail_params).json()\n","    website = requests.get(actual_url)\n","    soup = BeautifulSoup(website.text, 'html.parser')\n","\n","    cast_cards = soup.find_all('li', class_='card')\n","    actors = [tag.get_text() for tag in cast_cards]\n","    actors_with_roles = [actor.strip() for actor in actors]\n","    actors_without_roles = [item.split('\\n')[0] for item in actors_with_roles]\n","\n","    keyword_cards = soup.find_all('section', class_='keywords right_column')\n","    keywords = [tag.get_text()[11:] for tag in keyword_cards]\n","    keywords_cleaned = [actor.strip().replace('\\n', ', ') for actor in keywords]\n","\n","    director_card = soup.find_all('ol', class_='people no_image')\n","    director_text = [tag.get_text() for tag in director_card]\n","    director_text_cleaned = [item.split('\\n')[2] for item in director_text]\n","\n","    title = movie_details.get('title')\n","    overview = movie_details.get('overview')\n","    director = director_text_cleaned\n","    genre_name = [genre['name'] for genre in movie_details['genres']]\n","\n","    return {\n","        'title': title,\n","        'director': director,\n","        'overview': overview,\n","        'genre_names': genre_name,\n","        'actors': actors_without_roles,\n","        'keywords': keywords_cleaned,\n","    }\n","\n","movie_info = get_movie_details(movie_title)"]},{"cell_type":"code","source":["def create_soup_from_scraped_dict(movie):\n","    # 1. Clean and tokenize lists (Director, Genres, Actors)\n","    def clean_and_join(items):\n","        if isinstance(items, list):\n","            # Remove spaces and lowercase everything\n","            return [str(i).replace(\" \", \"\").lower() for i in items]\n","        return []\n","\n","    # 2. Special handling for your 'keywords' string\n","    # Splits \"car race, villain\" into ['carrace', 'villain']\n","    raw_keywords = movie.get('keywords', '')\n","    # Ensure raw_keywords is a string before splitting\n","    if isinstance(raw_keywords, list):\n","        raw_keywords = \", \".join(raw_keywords)\n","    keywords_list = [k.strip().replace(\" \", \"\").lower() for k in raw_keywords.split(',')]\n","\n","    # 3. Process the other fields\n","    director = clean_and_join(movie.get('director', []))\n","    genres = clean_and_join(movie.get('genre_names', []))\n","    actors = clean_and_join(movie.get('actors', []))[:]\n","\n","    # 4. Overview stays as natural language (just lowercase)\n","    overview = movie.get('overview', '').lower()\n","\n","    # 5. Create the Final String Combine everything into one \"soup\"\n","    soup = \" \".join(director) + \" \" + \" \".join(genres) + \" \" + \" \".join(keywords_list) + \" \" + \" \".join(actors) + \" \" + overview\n","\n","    return soup"],"metadata":{"id":"tpfpKjdMw0QH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('movies.csv')\n","\n","# 1. Process the CONTENT of the 'cast' column\n","def joinall(x):\n","    if isinstance(x, list):\n","        return [str.lower(i.replace(\" \", \"\")) for i in x]\n","    return str.lower(str(x).replace(\" \", \"\"))\n","\n","# Apply cleaning to specific columns to create unique tokens\n","data['cast'] = data['cast'].apply(joinall)\n","data['director'] = data['director'].apply(joinall)\n","data['genres'] = data['genres'].apply(joinall)\n","data['keywords'] = data['keywords'].apply(joinall)\n","\n","# 2. Select the existing columns we need\n","relevant = ['genres', 'keywords', 'overview', 'title', 'cast', 'director', 'vote_average']\n","needed = data[relevant].copy()\n","needed = needed.fillna('')\n","\n","# 3. Create the text soup. Since 'cast' and 'director' are now cleaned (joined names), they act as unique IDs in this string.\n","def create_soup(x):\n","  return (x['director'] + ' ') * 5 + \\\n","           (x['keywords'] + ' ') * 4 + \\\n","           (x['genres'] + ' ') * 3 + \\\n","           (x['cast'] + ' ') + \\\n","           (x['overview'])\n","  # return (x['director'] + ' ') * 5 + (x['keywords'] + ' ') * 4 + (x['genres'] + ' ') * 3 + x['cast'] + ' ' + x['overview']\n","\n","needed['soup'] = needed.apply(create_soup, axis=1)\n","\n","# 4. Initialize the Vectorizer and Similarity\n","tfidf = TfidfVectorizer(stop_words='english')\n","csv_matrix = tfidf.fit_transform(needed['soup']) # Changed to fit_transform\n","scraped_matrix = tfidf.transform([create_soup_from_scraped_dict(movie_info)])\n","cosine_sim = cosine_similarity(scraped_matrix, csv_matrix)\n","\n","# 5. Setup for lookup to ensure data index matches cosine_sim index\n","data = data.reset_index(drop=True)\n","# The 'indices' series is no longer needed for recommendations for scraped movies\n","# indices = pd.Series(data.index, index=data['title']).drop_duplicates()\n","\n","# Modified function to get recommendations for a scraped movie\n","def get_recommendations_for_scraped_movie(scraped_movie_similarity_scores, data_df, input_title=movie_info['title']):\n","    sim_scores = list(enumerate(scraped_movie_similarity_scores))\n","    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n","\n","    qualified_movies_indices = []\n","    qualified_movies_scores = []\n","\n","    for i, score in sim_scores:\n","        current_title = data_df.iloc[i]['title']\n","        movie_rating = data_df.iloc[i]['vote_average']\n","\n","        # NEW FILTER: Skip if the title matches the input movie\n","        if current_title.lower() == input_title.lower():\n","            continue\n","\n","        if movie_rating > 6.5:\n","            qualified_movies_indices.append(i)\n","            qualified_movies_scores.append(score)\n","\n","        # Stop once we have 10 good recommendations\n","        if len(qualified_movies_indices) == 10:\n","            break\n","\n","    recommendations = pd.DataFrame({\n","        'Movie Title': data_df['title'].iloc[qualified_movies_indices].values,\n","        'Similarity Score': qualified_movies_scores,\n","        'Rating': data_df['vote_average'].iloc[qualified_movies_indices].values\n","    })\n","    return recommendations\n","# Call the new function with the cosine_sim[0] and the data DataFrame\n","print(get_recommendations_for_scraped_movie(cosine_sim[0], data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K171LhkPnTlv","executionInfo":{"status":"ok","timestamp":1767180322487,"user_tz":-330,"elapsed":770,"user":{"displayName":"Himeth Sigera","userId":"17456125594711327945"}},"outputId":"07f5c6b0-4512-44e8-893b-507ef1f42c5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                    Movie Title  Similarity Score  Rating\n","0                  Midnight Run          0.111047     7.2\n","1                  Billy Elliot          0.061251     7.4\n","2                      Salvador          0.042236     7.0\n","3       The Wolf of Wall Street          0.038474     7.9\n","4           The Lives of Others          0.037236     7.9\n","5  The Texas Chain Saw Massacre          0.037023     7.2\n","6                   Margin Call          0.035948     6.7\n","7                 The Godfather          0.035062     8.4\n","8                     Eden Lake          0.033429     6.7\n","9      Night of the Living Dead          0.032429     7.5\n"]}]}]}